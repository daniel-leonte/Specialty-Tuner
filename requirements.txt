torch>=2.0.0
transformers>=4.30.0
peft>=0.4.0
datasets>=2.12.0
black>=23.3.0
accelerate>=0.20.0
bitsandbytes>=0.39.0  # For 4-bit quantization
scipy>=1.10.0
numpy>=1.24.0
tqdm>=4.65.0
sentencepiece>=0.1.99  # For tokenizers
protobuf>=3.20.0  # Required by some transformers dependencies 